{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "buV9E0bf-37g"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Social Network Analysis"
      ],
      "metadata": {
        "id": "buV9E0bf-37g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTING THE DATA SCIENCE LIBRARIES"
      ],
      "metadata": {
        "id": "HNvHInaq_BMJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eum2WGOnBeeL"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the ML / Scikit learn EVERYTHING"
      ],
      "metadata": {
        "id": "egI1aKHM_G4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "rw9qEruauW9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split               #for splitting the data into test and training data\n",
        "from sklearn.compose import ColumnTransformer                       #for transforming the columns\n",
        "from sklearn.impute import SimpleImputer                             #for imputing the missing values\n",
        "from sklearn.preprocessing import OneHotEncoder                      #one hot encoding\n",
        "from sklearn.preprocessing import MinMaxScaler                        #standard scaling\n",
        "\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score                 # for accuracy score\n",
        "from sklearn.model_selection import cross_val_score        # for cross validation score\n",
        "\n",
        "from sklearn.linear_model import LinearRegression           # Import the LinearRegression class\n",
        "from sklearn.metrics import mean_squared_error, r2_score    # to find out the error functions\n",
        "from sklearn.preprocessing import PolynomialFeatures , StandardScaler   # for the polunomial features\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Ridge   # ridge Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier                 #Decision tree\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier   # bagging and Boosting\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score   # different metrices to check how our model performed"
      ],
      "metadata": {
        "id": "wRReSbVmlxcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Deep learning Everything"
      ],
      "metadata": {
        "id": "7EOOII0y82hE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "O1qjFngb87Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing mathematical models"
      ],
      "metadata": {
        "id": "5oPnYaeAM0_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: import the mathematical testing framewroks\n",
        "\n",
        "# Importing mathematical models\n",
        "import math\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "import scipy.stats as stats\n",
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "G_2PyN5pNV1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Information about the Dataset"
      ],
      "metadata": {
        "id": "XTPRT3iy9EuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files    # we are importing the file from the device\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "GiKUuK2LUcY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorical encoding has already being performed"
      ],
      "metadata": {
        "id": "u9tMczjh9x1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('Social_Network_Ads.csv')   #fitting the data in the df dataframe\n",
        "df.head(5)\n",
        "\n"
      ],
      "metadata": {
        "id": "PAXRZRNaJVKO",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n"
      ],
      "metadata": {
        "id": "fkHEM3gG747n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "tI7KmcrM79Sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()       # we are checking for the null values luckily we dont have any here"
      ],
      "metadata": {
        "id": "i0p4tkGa8LcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " There is no null data present in our Dataset"
      ],
      "metadata": {
        "id": "wUxiZbKg8QuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('User ID', axis=1)"
      ],
      "metadata": {
        "id": "4Ry4LNPxHc0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "wWsagzup5Wxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['Purchased','Gender'], axis=1)\n",
        "y = df['Purchased']"
      ],
      "metadata": {
        "id": "1F8TrMvc6eha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "YejYsqJn6geY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "nk94-rNb6jXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Standard Scaling the data"
      ],
      "metadata": {
        "id": "1zEU_b-o8U6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "2Pihsgkv8YrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Test Split"
      ],
      "metadata": {
        "id": "VcbKVrXq7Jk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "lMc_1qWa7Qb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "Z5GHL4Jn7Y7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "5da2Cer_7b1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selecting the Value of K"
      ],
      "metadata": {
        "id": "-Ho325_v86JK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We Select the Value of K on the basis of 2 mathods\n",
        "1 - Square-rooting the total no of Rows\n",
        "2 - Experimenting with Different no values of k"
      ],
      "metadata": {
        "id": "qzemPeRt9WEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k1 = np.sqrt(len(X_train))\n",
        "k1 = int(k1)\n",
        "k1"
      ],
      "metadata": {
        "id": "O2ZMPqfd89XO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying the KNN Algorithm"
      ],
      "metadata": {
        "id": "tLJal2Se93JH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "clf1  = KNeighborsClassifier(n_neighbors=k1)    # k1 = 17\n",
        "clf2  = KNeighborsClassifier(n_neighbors=5)     # k2 = 5\n",
        "clf3  = KNeighborsClassifier(n_neighbors=11)    # k3 = 10\n",
        "clf4  = KNeighborsClassifier(n_neighbors=14)    # k4 = 14\n",
        "clf5  = KNeighborsClassifier(n_neighbors=20)    # k5 = 20\n",
        "\n"
      ],
      "metadata": {
        "id": "jFRVOzTm-tbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf1.fit(X_train, y_train)      # Fitting of the different KNN with different values of N\n",
        "clf2.fit(X_train, y_train)\n",
        "clf3.fit(X_train, y_train)\n",
        "clf4.fit(X_train, y_train)\n",
        "clf5.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "oB9qIx3R-w_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred1 = clf1.predict(X_test)    # Prediction of the different classifiers\n",
        "y_pred2 = clf2.predict(X_test)\n",
        "y_pred3 = clf3.predict(X_test)\n",
        "y_pred4 = clf4.predict(X_test)\n",
        "y_pred5 = clf5.predict(X_test)"
      ],
      "metadata": {
        "id": "FufhAjYx-4j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Calculate accuracy\n",
        "print ( accuracy_score(y_test, y_pred1))\n",
        "print ( accuracy_score(y_test, y_pred2))\n",
        "print ( accuracy_score(y_test, y_pred3))\n",
        "print ( accuracy_score(y_test, y_pred4))\n",
        "print ( accuracy_score(y_test, y_pred5))\n"
      ],
      "metadata": {
        "id": "oJp9vZdNIPEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a FUnction for the Prediction of Age"
      ],
      "metadata": {
        "id": "DQOghGZ9JnNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_output():\n",
        "\n",
        "  age = int(input(\"Enter the Age: \"))        # We input the data Age and Salary\n",
        "  salary = int(input(\"Enter the Salary: \"))\n",
        "\n",
        "  X_new = np.array([[age,salary]])       # Put the inputed data into the array\n",
        "  X_new = scaler.transform(X_new)        # Scaling and transforming the array\n",
        "\n",
        "  y_pred = clf5.predict(X_new)           # As Clf5 gave us the most accuracy of 94%\n",
        "  print(y_pred)                          # Prediction of the data"
      ],
      "metadata": {
        "id": "AlbHwlQBJr3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_output()"
      ],
      "metadata": {
        "id": "hkl46x8UKToN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}