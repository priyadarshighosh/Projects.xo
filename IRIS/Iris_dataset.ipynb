{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree : Case Study ( Iris Dataset )\n",
        "\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "u93QB4H8gs0F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTING DATA SCIENCE LIBRARIES"
      ],
      "metadata": {
        "id": "I2xjrloHcxJQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JF9RMWnFZYq3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORT MACHINE LEARNING LIBRARIES AND CLASSES"
      ],
      "metadata": {
        "id": "-FDeOVL3M7rU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split               #for splitting the data into test and training data\n",
        "from sklearn.compose import ColumnTransformer                       #for transforming the columns\n",
        "from sklearn.impute import SimpleImputer                             #for imputing the missing values\n",
        "from sklearn.preprocessing import OneHotEncoder                      #one hot encoding\n",
        "from sklearn.preprocessing import MinMaxScaler                        #standard scaling\n",
        "\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score                 # for accuracy score\n",
        "from sklearn.model_selection import cross_val_score        # for cross validation score\n",
        "\n",
        "from sklearn.linear_model import LinearRegression           # Import the LinearRegression class\n",
        "from sklearn.metrics import mean_squared_error, r2_score    # to find out the error functions\n",
        "from sklearn.preprocessing import PolynomialFeatures , StandardScaler   # for the polunomial features\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Ridge   # ridge Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix , precision_score , recall_score , f1_score\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import plot_tree\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import rcParams\n"
      ],
      "metadata": {
        "id": "msp3HMUHkMNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Information about the Dataset"
      ],
      "metadata": {
        "id": "XTPRT3iy9EuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files    # we are importing the file from the device\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "GiKUuK2LUcY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df=pd.read_csv('Iris_transformed.csv')   #fitting the data in the df dataframe\n",
        "df.head()"
      ],
      "metadata": {
        "id": "PAXRZRNaJVKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['Species' ,'Id'])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "k5OLAkTPxbBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "vqiDIdPqxmAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "qnK5Q5flxqhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X=df.drop(columns=['Species_Numeric'])\n",
        "y=df['Species_Numeric']\n",
        "\n",
        "X_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "8sgooIkFWCtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalizing the Dataset"
      ],
      "metadata": {
        "id": "3ECUFDqbxjRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalize = MinMaxScaler()\n",
        "\n",
        "X = normalize.fit_transform(X)\n",
        "X"
      ],
      "metadata": {
        "id": "yN84GpLFx0vU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.2,random_state=42)  # now train test split after normalization"
      ],
      "metadata": {
        "id": "Ozh3jXsRygsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "Ur7cvPOElZU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now we gonna fit the data to  Decision Tree"
      ],
      "metadata": {
        "id": "l2ZfBvipXfW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix , precision_score , recall_score , f1_score"
      ],
      "metadata": {
        "id": "JZ9YjmpzXqQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "DcOA_kngX1t2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(X_test)\n"
      ],
      "metadata": {
        "id": "sUMGjuwrYaet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization of the Decision Tree"
      ],
      "metadata": {
        "id": "iv08kWrQstLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import plot_tree\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import rcParams\n",
        "\n",
        "rcParams['figure.figsize'] = 80,50\n",
        "\n",
        "plot_tree(clf)"
      ],
      "metadata": {
        "id": "1mTWLGitsy83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ct7F9TSKJYij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating Metrices before GridSearchCV"
      ],
      "metadata": {
        "id": "oIUCCMoIYDGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('Accuracy of Decision Tree:' , accuracy_score(y_test , y_pred )  )"
      ],
      "metadata": {
        "id": "nVQ2hnHRYF8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test , y_pred)"
      ],
      "metadata": {
        "id": "7fu-T1XbyobJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision_score(y_test , y_pred , average=None)"
      ],
      "metadata": {
        "id": "BoLOfXiBy2NK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recall_score(y_test , y_pred , average=None)"
      ],
      "metadata": {
        "id": "SEXucj-ky_On"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(y_test , y_pred , average=None)"
      ],
      "metadata": {
        "id": "59ZLtr8gzDpk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}