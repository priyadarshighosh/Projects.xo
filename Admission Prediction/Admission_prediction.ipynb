{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  Prediction  and Classification of Admission of Students"
      ],
      "metadata": {
        "id": "buV9E0bf-37g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTING THE DATA SCIENCE LIBRARIES"
      ],
      "metadata": {
        "id": "HNvHInaq_BMJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eum2WGOnBeeL"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the ML / Scikit learn EVERYTHING"
      ],
      "metadata": {
        "id": "egI1aKHM_G4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "rw9qEruauW9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split               #for splitting the data into test and training data\n",
        "from sklearn.compose import ColumnTransformer                       #for transforming the columns\n",
        "from sklearn.impute import SimpleImputer                             #for imputing the missing values\n",
        "from sklearn.preprocessing import OneHotEncoder                      #one hot encoding\n",
        "from sklearn.preprocessing import MinMaxScaler                        #standard scaling\n",
        "\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score                 # for accuracy score\n",
        "from sklearn.model_selection import cross_val_score        # for cross validation score\n",
        "\n",
        "from sklearn.linear_model import LinearRegression           # Import the LinearRegression class\n",
        "from sklearn.metrics import mean_squared_error, r2_score    # to find out the error functions\n",
        "from sklearn.preprocessing import PolynomialFeatures , StandardScaler   # for the polunomial features\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Ridge   # ridge Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier                 #Decision tree\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier   # bagging and Boosting\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score   # different metrices to check how our model performed"
      ],
      "metadata": {
        "id": "wRReSbVmlxcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Deep learning Everything"
      ],
      "metadata": {
        "id": "7EOOII0y82hE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "O1qjFngb87Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing mathematical models"
      ],
      "metadata": {
        "id": "5oPnYaeAM0_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: import the mathematical testing framewroks\n",
        "\n",
        "# Importing mathematical models\n",
        "import math\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "import scipy.stats as stats\n",
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "G_2PyN5pNV1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading  the Dataset"
      ],
      "metadata": {
        "id": "XTPRT3iy9EuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files    # we are importing the file from the device\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "GiKUuK2LUcY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Information about the Dataset"
      ],
      "metadata": {
        "id": "r-j7Cd4ShO5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('Admission_Dataset.csv')   #fitting the data in the df dataframe\n",
        "df.head(5)\n",
        "\n"
      ],
      "metadata": {
        "id": "PAXRZRNaJVKO",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= df.drop(['Serial No.'],axis=1)\n",
        "df.head()              # we are removing all identity column"
      ],
      "metadata": {
        "id": "S8NGGeR9xk0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n"
      ],
      "metadata": {
        "id": "fkHEM3gG747n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "tI7KmcrM79Sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()       # we are checking for the null values luckily we dont have any here"
      ],
      "metadata": {
        "id": "i0p4tkGa8LcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " There is no null data present in our Dataset"
      ],
      "metadata": {
        "id": "wUxiZbKg8QuQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "YP84BY9b8Zdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()          # Checking the Duplicate Columns"
      ],
      "metadata": {
        "id": "iUBfdUMF8dqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['University Rating'].value_counts()          # this is kind of both categorical also numerical also thats why\n",
        "                                                    # we need to fo some work here"
      ],
      "metadata": {
        "id": "5zK3PhHsyiNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['SOP'].value_counts()"
      ],
      "metadata": {
        "id": "USE8VES2zFSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['LOR '].value_counts()"
      ],
      "metadata": {
        "id": "4i7qCI7OzSf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Admit'] = df['Chance of Admit '].apply(lambda x: 1 if x >= 0.65 else 0)  # This column will be used for Classification as it is a Binary Value"
      ],
      "metadata": {
        "id": "Ku7vbTukhAde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "ZHFZxZ6WhYZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Chance of Admit '] =  df['Chance of Admit '] * 10 + 0.5  # This column will be used for prediction as it is a INTEGER VALUE\n",
        "df['Chance of Admit '] =  df['Chance of Admit '] // 1"
      ],
      "metadata": {
        "id": "GW5uyNi1bEvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "6uE0qYJPgsUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "_cHaF2bjEJgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Chance of Admit '].value_counts()       # IF we calculate  the no of students based on the Percentages - We gonna get 362 - we take 70perc of the 136 = 95 , like this we will add for each percentage level"
      ],
      "metadata": {
        "id": "vUUtpb3XRChy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Admit'].value_counts()                 # here we get 372 - the diffeence may come from the fact"
      ],
      "metadata": {
        "id": "iJxmwNJXRMHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " #  Encoding the Categorical Values"
      ],
      "metadata": {
        "id": "54GFBIsKAA4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoders = {}\n",
        "categorical_columns = [            # these are the only 2 string type categorical values\n",
        "    'University Rating' , 'Research'\n",
        "]\n",
        "\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()                         # we are label encoding the categorical values\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le"
      ],
      "metadata": {
        "id": "RwFzWD_NAEbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7FJKVu1OEqaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Standard Scaling the numeric values"
      ],
      "metadata": {
        "id": "p7-0H-rSAg7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "HA-b0z5ClJzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_columns =  ['GRE Score', 'TOEFL Score',  'SOP', 'LOR ', 'CGPA']\n",
        "\n",
        "\n",
        "def remove_outliers(df , columns ):       # Outlier detection of the Numeric columns\n",
        "  for col in columns:\n",
        "\n",
        "    Q1 = df[col].quantile(0.25)            # 25th percentile\n",
        "    Q3 = df[col].quantile(0.75)               # 75th percentile\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    lower_bound = Q1 - 1.5 * IQR           # lower bound and upper bound a little less than 25th percentile and little more than 75th percentile\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
        "\n",
        "  return df\n",
        "\n",
        "df = remove_outliers(df , numerical_columns)"
      ],
      "metadata": {
        "id": "XePWWals8sqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "KND3ot6zltuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_columns =  ['GRE Score', 'TOEFL Score',  'SOP', 'LOR ', 'CGPA']\n"
      ],
      "metadata": {
        "id": "J9NXMB508jG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])"
      ],
      "metadata": {
        "id": "F-OkP875As0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "N0rDH33Tl8Ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are using Inter-quartile Range to find the ouliers in the Numerical Continuous Values of the Numerical columns that we have"
      ],
      "metadata": {
        "id": "hLGjtdxj-gIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "hr_0O7UqGdpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis ( EDA )"
      ],
      "metadata": {
        "id": "4PmJ4wEfBBUV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Distribution of NUMERIC FEATURES and Analysis"
      ],
      "metadata": {
        "id": "noe8bZQyhtlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_columns =  ['GRE Score', 'TOEFL Score',  'SOP', 'LOR ', 'CGPA']\n",
        "categorical_columns = [ 'University Rating' , 'Research'  ]"
      ],
      "metadata": {
        "id": "ReWt9Bx5-uUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution plots for numerical features\n",
        "plt.figure(figsize=(18, 18))\n",
        "\n",
        "\n",
        "for i, col in enumerate(numerical_columns):\n",
        "    plt.subplot(4, 3, i + 1)\n",
        "    sns.histplot(df[col], bins=30, kde=True , palette='Set3')\n",
        "    plt.title(f'{col} Distribution')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Count')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vIOVnALRFzbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gives us the 4 graphs for 4 features that we had\n",
        "\n",
        "All the graphs are basically distribution graphs removing the Outliers"
      ],
      "metadata": {
        "id": "NVnj2FGsGLLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Box plots for numerical features grouped by Prediction\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "\n",
        "for i, col in enumerate(numerical_columns):\n",
        "    plt.subplot(4, 3, i + 1)\n",
        "    sns.boxplot(x='Chance of Admit ', y=col, data=df , palette='Set2')\n",
        "    plt.title(f'{col} by Chance of Admit ')\n",
        "    plt.xlabel('Chance of Admit ')\n",
        "    plt.ylabel(col)\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "93R5_BR9G909"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " We draw graphs of Species  with all their Numerical features such as 4 features given above ."
      ],
      "metadata": {
        "id": "m5CHMObAHZq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Box plots for numerical features grouped by Classification\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "\n",
        "for i, col in enumerate(numerical_columns):\n",
        "    plt.subplot(4, 3, i + 1)\n",
        "    sns.boxplot(x='Admit', y=col, data=df , palette='Set2')\n",
        "    plt.title(f'{col} by  Admit')\n",
        "    plt.xlabel('Admit')\n",
        "    plt.ylabel(col)\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZHrkdQkRm8a-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Categorical Features Analysis"
      ],
      "metadata": {
        "id": "OdsvrnIDiP4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Q4TCyCFAng-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count plots for categorical features GROUPED BY SPECIES\n",
        "categorical_columns = [ 'University Rating' , 'Research'  ]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "\n",
        "\n",
        "for i, col in enumerate(categorical_columns):\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    sns.histplot(x=col, data=df , palette='Set1')\n",
        "    plt.title(f'{col} Count')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Count')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hhZJk6LMH9XF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Group by species and sex to count occurrences\n",
        "df_grouped = df.groupby(['Admit', 'Research']).size().reset_index(name='count')\n",
        "\n",
        "# Plotting the barplot\n",
        "sns.barplot(x='Admit', y='count', hue='Research', data=df_grouped)\n",
        "\n",
        "# Display the plot\n",
        "plt.title('Research Count per Admit')\n",
        "plt.ylabel('Count')\n",
        "plt.xlabel('Admit')\n",
        "plt.xticks(rotation=45)  # Rotate species labels if needed\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oipvhQiulRN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by species and sex to count occurrences\n",
        "df_grouped = df.groupby(['Admit', 'University Rating']).size().reset_index(name='count')\n",
        "\n",
        "# Plotting the barplot\n",
        "sns.barplot(x='Admit', y='count', hue='University Rating', data=df_grouped)\n",
        "\n",
        "# Display the plot\n",
        "plt.title('University Rating Count per Admit')\n",
        "plt.ylabel('Count')\n",
        "plt.xlabel('Admit')\n",
        "plt.xticks(rotation=45)  # Rotate species labels if needed\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0MreMrxQ3jPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MULtivariate Analysis of the Numeric Features\n"
      ],
      "metadata": {
        "id": "BfaSA1LEiJyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_columns =  ['GRE Score', 'TOEFL Score',  'SOP', 'LOR ', 'CGPA' ,'Admit']"
      ],
      "metadata": {
        "id": "9nk_b8EL6moQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pairplot to show relationships between features\n",
        "plt.figure(figsize=(15, 15))\n",
        "sns.pairplot(df[numerical_columns], hue='Admit')#, palette='Set2')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7Itj5PJ5LLYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above wasnt that much helpful to be honest"
      ],
      "metadata": {
        "id": "Gx2x8Rclg7kD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap\n",
        "plt.figure(figsize=(20, 15))\n",
        "numeric_data = df[numerical_columns]\n",
        "sns.heatmap(numeric_data.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qnaGIC8WL9xZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This was still kind of helpful  as Exited is HEavily corelated to Age and midlly corelated to Estimated Salary ."
      ],
      "metadata": {
        "id": "iWEG45DmhAAh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correlation with the Admit"
      ],
      "metadata": {
        "id": "i6kCaRieiPPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "COA_corr = pd.DataFrame(df.corr()['Admit'])\n",
        "COA_corr.rename({'Admit': 'Correlation Coeffecient'}, axis=1, inplace=True)\n",
        "COA_corr.drop('Admit', inplace=True)\n",
        "COA_corr.sort_values(['Correlation Coeffecient'], ascending=False, inplace=True)\n",
        "COA_corr_x = COA_corr.index\n",
        "COA_corr_y = COA_corr['Correlation Coeffecient']\n",
        "sns.barplot(y=COA_corr_x,x=COA_corr_y).set_title('Admit Correlation Coeffecients', size='30')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PX0z5XLbiUX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COA_corr"
      ],
      "metadata": {
        "id": "PQpLAMa_itvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COA_corr = pd.DataFrame(df.corr()['Chance of Admit '])\n",
        "COA_corr.rename({'Chance of Admit ': 'Correlation Coeffecient'}, axis=1, inplace=True)\n",
        "COA_corr.drop('Chance of Admit ', inplace=True)\n",
        "COA_corr.sort_values(['Correlation Coeffecient'], ascending=False, inplace=True)\n",
        "COA_corr_x = COA_corr.index\n",
        "COA_corr_y = COA_corr['Correlation Coeffecient']\n",
        "sns.barplot(y=COA_corr_x,x=COA_corr_y).set_title('Chance of Admit Correlation Coeffecients', size='30')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pqkm1r75tbSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COA_corr"
      ],
      "metadata": {
        "id": "Q21A_XV-tpNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression and Classification Algorithms on the Entire Dataset"
      ],
      "metadata": {
        "id": "MhDL52jIPpKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('Chance of Admit ', axis=1)\n",
        "y = df['Chance of Admit ']\n"
      ],
      "metadata": {
        "id": "5SiTBSg2jaK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-Test Split on the Columns"
      ],
      "metadata": {
        "id": "iu_OoX6LjfJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "LH702qNkjjSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression Model  ( Supervised Machine Learning )"
      ],
      "metadata": {
        "id": "qiiHxj0hjMjt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying the Regression  Algorithm"
      ],
      "metadata": {
        "id": "GcaChNlvj_t6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Putting all the Regression Models in the Dict named Models"
      ],
      "metadata": {
        "id": "KoVPoKOcodXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "!pip install xgboost\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from lightgbm import LGBMRegressor\n"
      ],
      "metadata": {
        "id": "WmiYBIgz8UB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Apply Regression  Learning Models\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge Regression': Ridge(),\n",
        "    'Lasso Regression': Lasso(),\n",
        "    'ElasticNet Regression': ElasticNet(),\n",
        "    'Decision Tree': DecisionTreeRegressor(),\n",
        "    'Random Forest': RandomForestRegressor(),\n",
        "    'SVM': SVR(),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(),\n",
        "    'Neural Network': MLPRegressor(max_iter=50),\n",
        "    'XGBoost': XGBRegressor(),\n",
        "    'LightGBM': LGBMRegressor(),\n",
        "    'K-Nearest Neighbors': KNeighborsRegressor()\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "ocwE4eU6kHoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are running a loop through models and fitting our data fir each and everymodel , and for each and everymodel we are calculating the R2 Score , MSE ,RMSE and MAE ."
      ],
      "metadata": {
        "id": "LOFUW0Ysom57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "results = []\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    #y_proba = model.predict_proba(X_test)#[:, #0]\n",
        "\n",
        "    results.append({\n",
        "        'Model': model_name,\n",
        "\n",
        "        'R2_score': r2_score(y_test, y_pred),\n",
        "        'MSE': mean_squared_error(y_test, y_pred),\n",
        "        #'RMSE': mean_squared_error(y_test, y_pred, squared=False),\n",
        "        'MAE': mean_absolute_error(y_test, y_pred)\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.sort_values(by='R2_score', ascending=False, inplace=True)\n",
        "\n",
        "results_df"
      ],
      "metadata": {
        "id": "r7cniJMenQIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As R2_score is most important parameter for Regression so we have have an ascending order list . But this is not giving us Satisfying results"
      ],
      "metadata": {
        "id": "S3n2n5GWo1Vu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Model  ( Supervised Machine Learning )"
      ],
      "metadata": {
        "id": "kuwkhM1crTzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('Admit', axis=1)\n",
        "y = df['Admit']\n"
      ],
      "metadata": {
        "id": "f8juyd6ZrTzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-Test Split on the Columns"
      ],
      "metadata": {
        "id": "AKUKM5XrrTzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "97ZC6BuzrTzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying the Classification  Algorithms"
      ],
      "metadata": {
        "id": "qN22FmmfrWoI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Putting all the Regression Models in the Dict named Models"
      ],
      "metadata": {
        "id": "KC64vNnsrWoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "!pip install xgboost\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from lightgbm import LGBMClassifier\n"
      ],
      "metadata": {
        "id": "O39TA8ro-zfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n"
      ],
      "metadata": {
        "id": "VOMlT68pyXyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Classification  Learning Models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=50),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'SVM': SVC(probability=True),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(),\n",
        "    'Neural Network': MLPClassifier(max_iter=50),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
        "    'Extra Trees': ExtraTreesClassifier(),\n",
        "    'XGBoost': XGBClassifier(),\n",
        "    'LightGBM': LGBMClassifier()\n",
        "}"
      ],
      "metadata": {
        "id": "JxO4NZD_P7WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\We are running a loop through models and fitting our data for each and everymodel , and for each and everymodel we are calculating the Accuracy , Recall , Precision , F1_score and ROC_AUC"
      ],
      "metadata": {
        "id": "abIu939KrWoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:, 0]\n",
        "\n",
        "    results.append({\n",
        "        'Model': model_name,\n",
        "        'Accuracy': accuracy_score(y_test, y_pred),\n",
        "\n",
        "        'Precision': precision_score(y_test, y_pred, average='weighted'),\n",
        "        'Recall': recall_score(y_test, y_pred, average='weighted'),\n",
        "        'F1 Score': f1_score(y_test, y_pred, average='weighted'),\n",
        "\n",
        "        'ROC-AUC': roc_auc_score(y_test, y_proba, multi_class='ovr' , average='weighted' )\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.sort_values(by='ROC-AUC', ascending=False, inplace=True)\n",
        "\n",
        "results_df"
      ],
      "metadata": {
        "id": "Th9G5oIvP96F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:, 0]\n",
        "\n",
        "    results.append({\n",
        "        'Model': model_name,\n",
        "        'Accuracy': accuracy_score(y_test, y_pred),\n",
        "\n",
        "        'Precision': precision_score(y_test, y_pred ),\n",
        "        'Recall': recall_score(y_test, y_pred),\n",
        "        'F1 Score': f1_score(y_test, y_pred),\n",
        "\n",
        "        'ROC-AUC': roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.sort_values(by='ROC-AUC', ascending=False, inplace=True)\n",
        "\n",
        "results_df"
      ],
      "metadata": {
        "id": "yTNgF55zA8_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion Matrix"
      ],
      "metadata": {
        "id": "cWnIAI1-4C3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "results = []\n",
        "\n",
        "for model_name, model in models.items():         #fitting , predicting and probablity\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:, 0] if hasattr(model, \"predict_proba\") else None\n",
        "\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)          # creating our C matrix\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)  # displaying it\n",
        "\n",
        "\n",
        "    disp.plot(cmap='Blues', ax=plt.gca())           # displaying the 6 graphs\n",
        "    plt.title(f'Confusion Matrix for {model_name}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "XLWIVzA48HXn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}